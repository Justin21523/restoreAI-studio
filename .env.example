# RestorAI MVP Configuration
# Copy this file to .env and modify as needed


# === Central AI Warehouse ===
AI_WAREHOUSE_ROOT=~/ai-warehouse                 # Root directory for all AI assets
MODELS_DIR=${AI_WAREHOUSE_ROOT}/models           # Override models location (defaults to AI_WAREHOUSE_ROOT/models)
DATASETS_DIR=${AI_WAREHOUSE_ROOT}/datasets       # Override cache location (defaults to AI_WAREHOUSE_ROOT/cache)
CACHE_DIR=${AI_WAREHOUSE_ROOT}/cache             # 中間結果/臨時快取

# Optional: 統一第三方快取（HF / Torch）
HF_HOME=${AI_WAREHOUSE_ROOT}/hf-cache
TRANSFORMERS_CACHE=${AI_WAREHOUSE_ROOT}/hf-cache
TORCH_HOME=${AI_WAREHOUSE_ROOT}/torch-cache

# === Device Configuration ===
DEVICE=cuda                        # cuda/cpu
USE_FP16=true                      # Use half precision for memory efficiency

# === Processing Settings ===
MAX_IMAGE_SIZE=2048                # Maximum image size (pixels)
TILE_SIZE=512                      # Tile size for memory efficiency
MAX_BATCH_SIZE=4                   # Maximum batch processing size

# === API Configuration ===
API_HOST=0.0.0.0                   # API server host
API_PORT=8000                      # API server port
API_TITLE=RestorAI MVP             # API title
API_DESCRIPTION=Lightweight AI image restoration API

# === UI Configuration ===
UI_PORT=7860                       # Gradio UI port
UI_SHARE=false                     # Share UI publicly (true/false)

# === Optional: Custom Model Paths ===
# ESRGAN_MODEL_PATH=./data/models/esrgan/RealESRGAN_x4plus.pth
# GFPGAN_MODEL_PATH=./data/models/gfpgan/GFPGANv1.4.pth
# RIFE_MODEL_PATH=./data/models/rife/flownet.pkl

# === Legacy Compatibility (optional) ===
# These paths are relative to project directory and used for input/output
# Models are always loaded from centralized warehouse above
INPUT_DIR=./data/input             # Input files directory
OUTPUT_DIR=./data/output           # Output files directory
TEMP_DIR=./data/temp               # Temporary files directory
